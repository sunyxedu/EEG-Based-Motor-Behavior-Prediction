{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:08.184886Z",
     "start_time": "2025-01-17T22:01:51.851415Z"
    },
    "id": "F9eZxkdC2l_4"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.bbci.de/competition/download/competition_iv/BCICIV_1_mat.zip\n",
    "# !unzip -q BCICIV_1_mat.zip\n",
    "# !rm -rf BCICIV_1_mat.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:08.322636Z",
     "start_time": "2025-01-17T22:04:08.188410Z"
    },
    "id": "0DGKsFl0mv3Y"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/XJTU-EEG/LibEER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.870464Z",
     "start_time": "2025-01-17T22:04:08.325922Z"
    },
    "id": "eVeoCU3N3DTD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import sys\n",
    "sys.path.append('LibEER/LibEER/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.887143Z",
     "start_time": "2025-01-17T22:04:09.871647Z"
    },
    "id": "VmdLAu5CndVO"
   },
   "outputs": [],
   "source": [
    "from DGCNN import DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.889325Z",
     "start_time": "2025-01-17T22:04:09.887738Z"
    },
    "id": "N65UofX72vnj"
   },
   "outputs": [],
   "source": [
    "TRAIN = ['a', 'b', 'd', 'e', 'g']\n",
    "VALID = ['c', 'f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.891848Z",
     "start_time": "2025-01-17T22:04:09.889955Z"
    },
    "id": "92-ucS3J5KVm"
   },
   "outputs": [],
   "source": [
    "# a - left, foot\n",
    "# b - left, right\n",
    "# c - left, right\n",
    "# d - left, right\n",
    "# e - left, right\n",
    "# f - left, foot\n",
    "# g - left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.894175Z",
     "start_time": "2025-01-17T22:04:09.892403Z"
    },
    "id": "CrulqTMpBYip"
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    'idle': 0,\n",
    "    'left' : 1,\n",
    "    'right': 2,\n",
    "    'foot': 3\n",
    "}\n",
    "\n",
    "LR = 1e-2\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:09.898605Z",
     "start_time": "2025-01-17T22:04:09.894974Z"
    },
    "id": "_GX7xq4nAkiC"
   },
   "outputs": [],
   "source": [
    "def get_labels(data):\n",
    "    N = len(data['cnt'])\n",
    "\n",
    "    labels = np.zeros((N, 4), dtype=np.uint8)\n",
    "    labels[:, 0] = 1\n",
    "\n",
    "    cls_labels = [d[0] for d in data['nfo'][0][0][1][0].tolist()]\n",
    "    timestamps = data['mrk'][0][0][0]\n",
    "    cls_idx = data['mrk'][0][0][1]\n",
    "\n",
    "    t1 = timestamps[np.where(cls_idx == 1)]\n",
    "    l1 = [0]*4\n",
    "    l1[LABELS[cls_labels[0]]] = 1\n",
    "    l1 = np.asarray([l1]*100)\n",
    "    for t in t1:\n",
    "        labels[t-50:t+50] = l1 # change to t :t+100\n",
    "\n",
    "    t2 = timestamps[np.where(cls_idx == -1)]\n",
    "    l2 = [0]*4\n",
    "    l2[LABELS[cls_labels[1]]] = 1\n",
    "    l2 = np.asarray([l2]*100)\n",
    "    for t in t2:\n",
    "        labels[t-50:t+50] = l2\n",
    "\n",
    "    return labels\n",
    "\n",
    "def get_data(data_id, split_size):\n",
    "    data = scipy.io.loadmat(f'BCICIV_calib_ds1{data_id}.mat')\n",
    "    eegs = data['cnt']\n",
    "    labels = get_labels(data)\n",
    "    np.savetxt(f\"labels_{data_id}.csv\", labels, delimiter=\",\", fmt=\"%d\")\n",
    "    \n",
    "    splits = range(split_size, len(eegs), split_size)\n",
    "\n",
    "    eegs_split = np.array_split(eegs, splits)[:-1]\n",
    "    labels_split = np.array_split(labels, splits)[:-1]\n",
    "    return eegs_split, labels_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:10.055856Z",
     "start_time": "2025-01-17T22:04:09.899150Z"
    },
    "id": "P3m9vQCzkxxG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_eegs, train_labels, valid_eegs, valid_labels = [], [], [], []\n",
    "\n",
    "for train_id in tqdm(TRAIN):\n",
    "    # print(train_id)\n",
    "    eegs_split, labels_split = get_data(train_id, split_size=200)\n",
    "    train_eegs.extend(eegs_split)\n",
    "    train_labels.extend(labels_split)\n",
    "\n",
    "for valid_id in tqdm(VALID):\n",
    "    eegs_split, labels_split = get_data(valid_id, split_size=100)\n",
    "    valid_eegs.extend(eegs_split)\n",
    "    valid_labels.extend(labels_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:10.062476Z",
     "start_time": "2025-01-17T22:04:10.058842Z"
    },
    "id": "F0c13UWekxqE"
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eegs, labels, split):\n",
    "        self.eegs = eegs\n",
    "        self.labels = labels\n",
    "        self.split = split\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        eeg, label = self.eegs[i], self.labels[i]\n",
    "        if self.split == 'train':\n",
    "            start_idx = random.randint(0, 100)\n",
    "            eeg = eeg[start_idx:start_idx+100]\n",
    "            label = label[start_idx:start_idx+100]\n",
    "\n",
    "        eeg = torch.from_numpy(eeg).float()\n",
    "        #eeg = (eeg - MEAN)/STD\n",
    "        eeg = (eeg - torch.mean(eeg, dim=0))/torch.std(eeg, dim=0)\n",
    "        eeg = eeg.transpose(0, 1)\n",
    "\n",
    "        # print(f\"Single sample shape: {eeg.shape}\")\n",
    "        \n",
    "        label_soft = torch.from_numpy(label).float().mean(dim=0)\n",
    "        #label_hard = torch.argmax(label_soft)\n",
    "        return eeg, label_soft\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = EEGDataset(train_eegs, train_labels, 'train')\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=0,\n",
    "                              shuffle=True, pin_memory=True, drop_last=True)\n",
    "n_train = len(dataloader_train)\n",
    "\n",
    "dataset_valid = EEGDataset(valid_eegs, valid_labels, 'valid')\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=0,\n",
    "                              shuffle=False, pin_memory=True, drop_last=False)\n",
    "n_valid = len(dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:10.069631Z",
     "start_time": "2025-01-17T22:04:10.067935Z"
    },
    "id": "e_ji2L13pS77"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:04:10.669027Z",
     "start_time": "2025-01-17T22:04:10.070114Z"
    },
    "id": "-NiQttp1mu0L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config/model_param/DGCNN.yaml may not exist or not available\n",
      "DGCNN Model, Parameters:\n",
      "\n",
      "k (The order of Chebyshev polynomials):                         2\n",
      "relu_is (The type of B_Relu func):                              1\n",
      "layers (The channels of each layers):        None                \n",
      "dropout rate:                                                 0.2\n",
      "\n",
      "Not Using Default Setting, the performance may be not the best\n",
      "Starting......\n",
      "Number of parameters: 0.98M\n"
     ]
    }
   ],
   "source": [
    "model = DGCNN(num_electrodes=59, in_channels=100, num_classes=4, k=2, relu_is=1, layers=None, dropout_rate=0.2)\n",
    "\n",
    "print(f'Number of parameters: {count_parameters(model):.2f}M')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# loss_name = \"Cross_Entropy\"\n",
    "\n",
    "# Calculate class weights based on label distribution\n",
    "labels = torch.stack([label for _, label in dataset_train])\n",
    "label_counts = torch.bincount(torch.argmax(labels, dim=1))\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "loss_name = \"Weighted_Cross_Entropy\"\n",
    "\n",
    "#grad_scaler = torch.amp.GradScaler('cuda')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=[0.9, 0.999], weight_decay=0.001)\n",
    "\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
    "#                                                steps_per_epoch=10, epochs=EPOCHS//10,\n",
    "#                                                pct_start=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in dataloader_train:\n",
    "#     print(\"Input shape:\", x.shape)\n",
    "#     print(\"Label shape:\", y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj: 0.0025\n",
      "adj_bias: 0.0100\n",
      "graphConvs.0.weight: 0.0003\n",
      "fc.weight: -0.0000\n",
      "fc.bias: 0.1000\n",
      "fc2.weight: -0.0015\n",
      "fc2.bias: 0.1000\n",
      "b_relus.0.bias: 0.0003\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:05:07.633383Z",
     "start_time": "2025-01-17T22:04:10.669640Z"
    },
    "id": "4RZEjEXJZ_bQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/1000  MPS Active  LR : 1.00E-02  Loss: 0.4192: 100%|██████████| 74/74 [00:01<00:00, 37.82it/s]\n",
      "Val Loss: 0.0589: 100%|██████████| 60/60 [00:00<00:00, 76.86it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1008\n",
      "Precision: ['0.8900', '0.0000', '0.0320', '0.0343']\n",
      "Recall: ['0.0783', '0.0000', '0.4600', '0.7100']\n",
      "FScore: ['0.1439', '0.0000', '0.0598', '0.0654']\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000  MPS Active  LR : 1.00E-02  Loss: 0.0557: 100%|██████████| 74/74 [00:01<00:00, 43.34it/s]\n",
      "Val Loss: 0.0829: 100%|██████████| 60/60 [00:00<00:00, 76.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.0491\n",
      "Precision: ['0.8462', '0.0515', '0.0165', '0.0000']\n",
      "Recall: ['0.0032', '0.8350', '0.0900', '0.0000']\n",
      "FScore: ['0.0064', '0.0970', '0.0278', '0.0000']\n",
      "Early stopping counter: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000  MPS Active  LR : 1.00E-02  Loss: 0.0453: 100%|██████████| 74/74 [00:01<00:00, 48.12it/s]\n",
      "Val Loss: 0.0484: 100%|██████████| 60/60 [00:00<00:00, 78.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1847\n",
      "Precision: ['0.8842', '0.0345', '0.0467', '0.0295']\n",
      "Recall: ['0.1768', '0.0050', '0.2300', '0.7700']\n",
      "FScore: ['0.2946', '0.0087', '0.0776', '0.0569']\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000  MPS Active  LR : 1.00E-02  Loss: 0.0433: 100%|██████████| 74/74 [00:01<00:00, 50.10it/s]\n",
      "Val Loss: 0.0693: 100%|██████████| 60/60 [00:00<00:00, 70.14it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.0302\n",
      "Precision: ['0.0000', '0.0000', '0.0276', '0.0833']\n",
      "Recall: ['0.0000', '0.0000', '1.0000', '0.1500']\n",
      "FScore: ['0.0000', '0.0000', '0.0536', '0.1071']\n",
      "Early stopping counter: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000  MPS Active  LR : 1.00E-02  Loss: 0.0448: 100%|██████████| 74/74 [00:01<00:00, 46.82it/s]\n",
      "Val Loss: 0.0542: 100%|██████████| 60/60 [00:00<00:00, 78.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1236\n",
      "Precision: ['0.8631', '0.2500', '0.0000', '0.0236']\n",
      "Recall: ['0.1146', '0.0050', '0.0000', '0.7900']\n",
      "FScore: ['0.2024', '0.0098', '0.0000', '0.0459']\n",
      "Early stopping counter: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000  MPS Active  LR : 1.00E-02  Loss: 0.0464: 100%|██████████| 74/74 [00:01<00:00, 48.76it/s]\n",
      "Val Loss: 0.0554: 100%|██████████| 60/60 [00:00<00:00, 77.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6872\n",
      "Precision: ['0.8992', '1.0000', '0.0000', '0.0439']\n",
      "Recall: ['0.7555', '0.0050', '0.0000', '0.4100']\n",
      "FScore: ['0.8211', '0.0100', '0.0000', '0.0794']\n",
      "Early stopping counter: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000  MPS Active  LR : 1.00E-02  Loss: 0.0442: 100%|██████████| 74/74 [00:01<00:00, 48.45it/s]\n",
      "Val Loss: 0.0968: 100%|██████████| 60/60 [00:00<00:00, 72.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1800\n",
      "Precision: ['0.9048', '0.0537', '0.0000', '0.0000']\n",
      "Recall: ['0.1504', '0.8650', '0.0000', '0.0000']\n",
      "FScore: ['0.2579', '0.1012', '0.0000', '0.0000']\n",
      "Early stopping counter: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000  MPS Active  LR : 5.00E-03  Loss: 0.0427: 100%|██████████| 74/74 [00:01<00:00, 48.97it/s]\n",
      "Val Loss: 0.0588: 100%|██████████| 60/60 [00:00<00:00, 79.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6618\n",
      "Precision: ['0.9006', '0.0678', '0.0317', '0.0515']\n",
      "Recall: ['0.7253', '0.0800', '0.1700', '0.1500']\n",
      "FScore: ['0.8035', '0.0734', '0.0534', '0.0767']\n",
      "Early stopping counter: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000  MPS Active  LR : 5.00E-03  Loss: 0.0379: 100%|██████████| 74/74 [00:01<00:00, 49.61it/s]\n",
      "Val Loss: 0.0541: 100%|██████████| 60/60 [00:00<00:00, 77.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1304\n",
      "Precision: ['0.8975', '0.0514', '0.0000', '0.0254']\n",
      "Recall: ['0.1052', '0.5100', '0.0000', '0.3600']\n",
      "FScore: ['0.1884', '0.0934', '0.0000', '0.0475']\n",
      "Early stopping counter: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000  MPS Active  LR : 5.00E-03  Loss: 0.0398: 100%|██████████| 74/74 [00:01<00:00, 51.27it/s]\n",
      "Val Loss: 0.0826: 100%|██████████| 60/60 [00:00<00:00, 75.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6106\n",
      "Precision: ['0.8966', '0.0637', '0.0369', '0.0000']\n",
      "Recall: ['0.6631', '0.2250', '0.2000', '0.0000']\n",
      "FScore: ['0.7624', '0.0993', '0.0623', '0.0000']\n",
      "Early stopping counter: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000  MPS Active  LR : 5.00E-03  Loss: 0.0393: 100%|██████████| 74/74 [00:01<00:00, 49.00it/s]\n",
      "Val Loss: 0.0554: 100%|██████████| 60/60 [00:00<00:00, 79.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.0525\n",
      "Precision: ['0.8784', '0.0530', '0.0515', '0.0196']\n",
      "Recall: ['0.0191', '0.4550', '0.0700', '0.3700']\n",
      "FScore: ['0.0373', '0.0949', '0.0593', '0.0373']\n",
      "Early stopping counter: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000  MPS Active  LR : 2.50E-03  Loss: 0.0368: 100%|██████████| 74/74 [00:01<00:00, 50.10it/s]\n",
      "Val Loss: 0.1018: 100%|██████████| 60/60 [00:00<00:00, 80.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5865\n",
      "Precision: ['0.9067', '0.1273', '0.0263', '0.0588']\n",
      "Recall: ['0.6409', '0.0700', '0.3300', '0.0200']\n",
      "FScore: ['0.7509', '0.0903', '0.0487', '0.0299']\n",
      "Early stopping counter: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000  MPS Active  LR : 2.50E-03  Loss: 0.0371: 100%|██████████| 74/74 [00:01<00:00, 50.72it/s]\n",
      "Val Loss: 0.0747: 100%|██████████| 60/60 [00:00<00:00, 76.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4285\n",
      "Precision: ['0.8995', '0.0561', '0.0320', '0.0417']\n",
      "Recall: ['0.4538', '0.1700', '0.3600', '0.1500']\n",
      "FScore: ['0.6033', '0.0844', '0.0588', '0.0652']\n",
      "Early stopping counter: 10/10\n",
      "Validation loss has increased for multiple epochs, stopping early!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Hyperparameters\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    cur_lr = f\"LR : {optimizer.param_groups[0]['lr']:.2E}\"\n",
    "\n",
    "    pbar_train = tqdm(dataloader_train, total=n_train, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "    mloss_train, mloss_val = 0.0, 0.0\n",
    "\n",
    "    for i, (x, y) in enumerate(pbar_train):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mloss_train += loss.item()\n",
    "\n",
    "        gpu_mem = (\n",
    "            f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\" if torch.cuda.is_available()\n",
    "            else \"MPS Active\" if torch.backends.mps.is_available()\n",
    "            else \"CPU Mode\"\n",
    "        )\n",
    "\n",
    "        pbar_train.set_description(f\"Epoch {epoch}/{EPOCHS}  {gpu_mem}  {cur_lr}  Loss: {mloss_train / (i + 1):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    pbar_val = tqdm(dataloader_valid, total=n_valid, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
    "\n",
    "    y_true, y_preds = [], []\n",
    "    for i, (x, y) in enumerate(pbar_val):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x)\n",
    "\n",
    "        loss = criterion(y_hat, y)\n",
    "        mloss_val += loss.item()\n",
    "        y_preds.append(y_hat)\n",
    "        y_true.append(y)\n",
    "\n",
    "        pbar_val.set_description(f\"Val Loss: {mloss_val / (i + 1):.4f}\")\n",
    "\n",
    "    y_true = torch.cat(y_true).cpu().numpy()\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    y_preds = F.softmax(torch.cat(y_preds), dim=1).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    accuracy = np.mean(y_true == y_preds)  \n",
    "    mets = precision_recall_fscore_support(y_true, y_preds, labels=[0, 1, 2, 3], average=None)\n",
    "\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    np.savetxt(\"validation_predictions.csv\", y_preds, delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "    print(f'Precision: {[f\"{p:.4f}\" for p in mets[0]]}')\n",
    "    print(f'Recall: {[f\"{r:.4f}\" for r in mets[1]]}')\n",
    "    print(f'FScore: {[f\"{f:.4f}\" for f in mets[2]]}')\n",
    "\n",
    "    # Early Stopping & Save Best Model\n",
    "    avg_val_loss = mloss_val / len(dataloader_valid)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f\"DGCNN_{loss_name}_best_model.pth\")\n",
    "        print(\"Best model saved!\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Early stopping counter: {counter}/{patience}\")\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Validation loss has increased for multiple epochs, stopping early!\")\n",
    "        break\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step(avg_val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
