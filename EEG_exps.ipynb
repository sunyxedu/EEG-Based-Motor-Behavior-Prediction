{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9eZxkdC2l_4"
      },
      "outputs": [],
      "source": [
        "!wget https://www.bbci.de/competition/download/competition_iv/BCICIV_1_mat.zip\n",
        "!unzip -q /content/BCICIV_1_mat.zip\n",
        "!rm -rf /content/BCICIV_1_mat.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DGKsFl0mv3Y"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/XJTU-EEG/LibEER.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVeoCU3N3DTD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import math\n",
        "import random\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/LibEER/LibEER/models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmdLAu5CndVO"
      },
      "outputs": [],
      "source": [
        "from DGCNN import DGCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N65UofX72vnj"
      },
      "outputs": [],
      "source": [
        "TRAIN = ['a', 'b', 'd', 'e', 'g']\n",
        "VALID = ['c', 'f']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92-ucS3J5KVm"
      },
      "outputs": [],
      "source": [
        "# a - left, foot\n",
        "# b - left, right\n",
        "# c - left, right\n",
        "# d - left, right\n",
        "# e - left, right\n",
        "# f - left, foot\n",
        "# g - left, right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrulqTMpBYip"
      },
      "outputs": [],
      "source": [
        "LABELS = {\n",
        "    'idle': 0,\n",
        "    'left' : 1,\n",
        "    'right': 2,\n",
        "    'foot': 3\n",
        "}\n",
        "\n",
        "LR = 1e-4\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GX7xq4nAkiC"
      },
      "outputs": [],
      "source": [
        "def get_labels(data):\n",
        "    N = len(data['cnt'])\n",
        "\n",
        "    labels = np.zeros((N, 4), dtype=np.uint8)\n",
        "    labels[:, 0] = 1\n",
        "\n",
        "    cls_labels = [d[0] for d in data['nfo'][0][0][1][0].tolist()]\n",
        "    timestamps = data['mrk'][0][0][0]\n",
        "    cls_idx = data['mrk'][0][0][1]\n",
        "\n",
        "    t1 = timestamps[np.where(cls_idx == 1)]\n",
        "    l1 = [0]*4\n",
        "    l1[LABELS[cls_labels[0]]] = 1\n",
        "    l1 = np.asarray([l1]*100)\n",
        "    for t in t1:\n",
        "        labels[t-50:t+50] = l1 # change to t :t+100\n",
        "\n",
        "    t2 = timestamps[np.where(cls_idx == -1)]\n",
        "    l2 = [0]*4\n",
        "    l2[LABELS[cls_labels[1]]] = 1\n",
        "    l2 = np.asarray([l2]*100)\n",
        "    for t in t2:\n",
        "        labels[t-50:t+50] = l2\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def get_data(data_id, split_size):\n",
        "    data = scipy.io.loadmat(f'/content/BCICIV_calib_ds1{data_id}.mat')\n",
        "    eegs = data['cnt']\n",
        "    labels = get_labels(data)\n",
        "\n",
        "    splits = range(split_size, len(eegs), split_size)\n",
        "\n",
        "    eegs_split = np.array_split(eegs, splits)[:-1]\n",
        "    labels_split = np.array_split(labels, splits)[:-1]\n",
        "    return eegs_split, labels_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3m9vQCzkxxG"
      },
      "outputs": [],
      "source": [
        "train_eegs, train_labels, valid_eegs, valid_labels = [], [], [], []\n",
        "\n",
        "for train_id in tqdm(TRAIN):\n",
        "    eegs_split, labels_split = get_data(train_id, split_size=200)\n",
        "    train_eegs.extend(eegs_split)\n",
        "    train_labels.extend(labels_split)\n",
        "\n",
        "for valid_id in tqdm(VALID):\n",
        "    eegs_split, labels_split = get_data(valid_id, split_size=100)\n",
        "    valid_eegs.extend(eegs_split)\n",
        "    valid_labels.extend(labels_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0c13UWekxqE"
      },
      "outputs": [],
      "source": [
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, eegs, labels, split):\n",
        "        self.eegs = eegs\n",
        "        self.labels = labels\n",
        "        self.split = split\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        eeg, label = self.eegs[i], self.labels[i]\n",
        "        if self.split == 'train':\n",
        "            start_idx = random.randint(0, 100)\n",
        "            eeg = eeg[start_idx:start_idx+100]\n",
        "            label = label[start_idx:start_idx+100]\n",
        "\n",
        "        eeg = torch.from_numpy(eeg).float()\n",
        "        #eeg = (eeg - MEAN)/STD\n",
        "        eeg = (eeg - torch.mean(eeg, dim=0))/torch.std(eeg, dim=0)\n",
        "        #eeg = eeg.transpose()\n",
        "\n",
        "        label_soft = torch.from_numpy(label).float().mean(dim=0)\n",
        "        #label_hard = torch.argmax(label_soft)\n",
        "        return eeg, label_soft\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eegs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNL55Uv_mhL8"
      },
      "outputs": [],
      "source": [
        "dataset_train = EEGDataset(train_eegs, train_labels, 'train')\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4,\n",
        "                              shuffle=True, pin_memory=True, drop_last=True)\n",
        "n_train = len(dataloader_train)\n",
        "\n",
        "dataset_valid = EEGDataset(valid_eegs, valid_labels, 'valid')\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4,\n",
        "                              shuffle=False, pin_memory=True, drop_last=False)\n",
        "n_valid = len(dataloader_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_ji2L13pS77"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NiQttp1mu0L"
      },
      "outputs": [],
      "source": [
        "model = DGCNN()\n",
        "print(f'Number of parameters: {count_parameters(model):.2f}M')\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "#grad_scaler = torch.amp.GradScaler('cuda')\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=[0.9, 0.999], weight_decay=0.0001)\n",
        "#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,\n",
        "#                                                steps_per_epoch=10, epochs=EPOCHS//10,\n",
        "#                                                pct_start=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqzKx2axE9Sf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RZEjEXJZ_bQ"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    cur_lr = f\"LR : {optimizer.param_groups[0]['lr']:.2E}\"\n",
        "\n",
        "    pbar_train = enumerate(dataloader_train)\n",
        "    pbar_train = tqdm(pbar_train, total=n_train, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
        "    mloss_train, mloss_val = 0.0, 0.0\n",
        "\n",
        "    for i, (x, y) in pbar_train:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mloss_train += loss.detach().item()\n",
        "\n",
        "        gpu_mem = f\"Mem : {torch.cuda.memory_reserved() / 1E9:.3g}GB\"\n",
        "        pbar_train.set_description((\"%10s  \" * 3 + \"%10s\") % (f\"Epoch {epoch}/{EPOCHS}\", gpu_mem, cur_lr,\n",
        "                                                              f\"Loss: {mloss_train / (i + 1):.4f}\"))\n",
        "\n",
        "    model.eval()\n",
        "    pbar_val = enumerate(dataloader_valid)\n",
        "    pbar_val = tqdm(pbar_val, total=n_valid, bar_format=\"{l_bar}{bar:10}{r_bar}{bar:-10b}\")\n",
        "\n",
        "    y_true, y_preds = [], []\n",
        "    for i, (x, y) in pbar_val:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_hat = model(x)\n",
        "\n",
        "        loss = criterion(y_hat, y)\n",
        "        mloss_val += loss.detach().item()\n",
        "        y_preds.append(y_hat)\n",
        "        y_true.append(y)\n",
        "\n",
        "        pbar_val.set_description((\"%10s\") % (f\"Val Loss: {mloss_val / (i+1):.4f}\"))\n",
        "\n",
        "    y_true = torch.cat(y_true, dim=0).argmax(dim=1).cpu().numpy()\n",
        "    y_preds = F.softmax(torch.cat(y_preds, dim=0), dim=1).argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    mets = precision_recall_fscore_support(y_true, y_preds, labels=[1, 2, 3], average=None)\n",
        "    print('Precision: ', mets[0])\n",
        "    print('Recall: ', mets[1])\n",
        "    print('FScore: ', mets[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNtd17XD8VQb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
